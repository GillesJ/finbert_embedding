2019-12-24 16:21:03,987 loading vocabulary file /home/abhijeet/Desktop/dl_projects/tf_tutorials/tf-finbert/finbert_embedding/finbertTRC2/vocab.txt
2019-12-24 16:21:04,004 loading archive file /home/abhijeet/Desktop/dl_projects/tf_tutorials/tf-finbert/finbert_embedding/finbertTRC2 from cache at /home/abhijeet/Desktop/dl_projects/tf_tutorials/tf-finbert/finbert_embedding/finbertTRC2
2019-12-24 16:21:04,004 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2019-12-24 16:21:05,037 Initialization Done !!
2019-12-24 16:21:05,070 Summing last 4 layers for each token
2019-12-24 16:21:05,070 ['another', 'psu', 'bank', ',', 'punjab', 'national', 'bank', 'which', 'also', 'reported', 'numbers', 'managed', 'to', 'see', 'a', 'slight', 'improvement', 'in', 'asset', 'quality', '.']
2019-12-24 16:21:05,070 Shape of Word Embeddings = 21
2019-12-24 16:21:05,070 Taking last layer embedding of each word.
2019-12-24 16:21:05,070 Mean of all words for sentence embedding.
2019-12-24 16:21:05,102 Shape of Sentence Embeddings = 768
