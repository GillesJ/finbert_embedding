2019-12-24 19:00:23,801 loading vocabulary file /home/abhijeet/Desktop/dl_projects/tf_tutorials/tf-finbert/finbert_embedding/finbert_embedding/model/vocab.txt
2019-12-24 19:00:23,819 loading archive file /home/abhijeet/Desktop/dl_projects/tf_tutorials/tf-finbert/finbert_embedding/finbert_embedding/model from cache at /home/abhijeet/Desktop/dl_projects/tf_tutorials/tf-finbert/finbert_embedding/finbert_embedding/model
2019-12-24 19:00:23,819 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2019-12-24 19:00:24,910 Initialization Done !!
2019-12-24 19:00:24,939 Summing last 4 layers for each token
2019-12-24 19:00:24,939 ['another', 'psu', 'bank', ',', 'punjab', 'national', 'bank', 'which', 'also', 'reported', 'numbers', 'managed', 'to', 'see', 'a', 'slight', 'improvement', 'in', 'asset', 'quality', '.']
2019-12-24 19:00:24,939 Shape of Word Embeddings = 21
2019-12-24 19:00:24,939 Taking last layer embedding of each word.
2019-12-24 19:00:24,940 Mean of all words for sentence embedding.
2019-12-24 19:00:24,967 Shape of Sentence Embeddings = 768
